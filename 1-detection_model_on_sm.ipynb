{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a641974c-888a-47c7-963f-04d6bf8aa56d",
   "metadata": {},
   "source": [
    "# FreeWheel Logo Detection模型训练指导"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42689b4a-271e-4d95-a660-4245b601b361",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. 准备LogoDet-3K数据到S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029292f5-e429-4d0d-bd37-bbeca011c086",
   "metadata": {
    "tags": []
   },
   "source": [
    "请运行如下脚本以安装实验需要使用的依赖，并将原始数据集准备好；请阅读脚本中的注释并进行对应的修改，以适配自己的环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ceb46d-9ffb-45c6-ab33-24829d84f184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 's5cmd'...\n",
      "remote: Enumerating objects: 11174, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 11174 (delta 0), reused 4 (delta 0), pack-reused 11167\u001b[K\n",
      "Receiving objects: 100% (11174/11174), 22.52 MiB | 26.59 MiB/s, done.\n",
      "Resolving deltas: 100% (5601/5601), done.\n",
      "100%|██████████████████████████████████████| 2.87G/2.87G [00:36<00:00, 85.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash ./logodet-prep.sh 1>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef7c0e-239b-4323-9fbe-409a79ec7823",
   "metadata": {},
   "source": [
    "处理logodet-3k数据，使其满足yolov8的数据格式\n",
    "\n",
    "LogoDet-3K/      \n",
    "|── cfg    \n",
    "|── datasets    \n",
    "|$~~~~~~~~~$|── images     \n",
    "│$~~~~~~~~~$|$~~~~~~~~~$|── train     \n",
    "|$~~~~~~~~~$|$~~~~~~~~~$|── val     \n",
    "|$~~~~~~~~~$|── labels     \n",
    "|$~~~~~~~~~$$~~~~~~~~~~$|── train   \n",
    "|$~~~~~~~~~$$~~~~~~~~~~$|── val   \n",
    "|── weights   \n",
    "\n",
    "- cfg文件夹中存储训练的配置文件，文件中指定训练数据和标注的路径，以及分类关系的映射\n",
    "- datasets中存储训练数据，请按照如下目录结构组织\n",
    "- （可选）weights文件夹中存储weights pt文件，可以基于一个以训练好的pt文件加载到模型中，然后进行增量训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b587a62-94cb-4334-968d-de8e8a0f5e15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:51<00:00,  5.71s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "准备logo3k数据，将logo3k数据集的标注数据转换成yolo格式，具体如何标注请参考此链接：\n",
    "https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#12-create-labels\n",
    "'''\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import xmltodict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 这个dict存储类别和ID的映射关系\n",
    "class_names_map = {'logo': 0}\n",
    "\n",
    "DET_DATA_DIR = 'train_data' # 训练数据目录\n",
    "LD3K_DATA_DIR = DET_DATA_DIR + '/' + 'LogoDet-3K' # logo3k数据目录\n",
    "LD3K_DS_DIR = LD3K_DATA_DIR + '/' + 'datasets' # logo3k训练数据集目录\n",
    "RAW_LD3K_DS_DIR = 'raw_data/LogoDet-3K' # logo3k原始数据存储目录\n",
    "\n",
    "sub_dirs = os.listdir(RAW_LD3K_DS_DIR)\n",
    "for sub_dir in tqdm(sub_dirs):\n",
    "    if 'DS_Store' not in sub_dir:\n",
    "        sub_sub_dirs = os.listdir(os.path.join(RAW_LD3K_DS_DIR, sub_dir))\n",
    "        for sub_sub_dir in sub_sub_dirs:\n",
    "            if 'DS_Store' not in sub_sub_dir:\n",
    "                filenames = os.listdir(os.path.join(RAW_LD3K_DS_DIR, sub_dir, sub_sub_dir))\n",
    "                for filename in filenames:\n",
    "                    old_filename = os.path.join(RAW_LD3K_DS_DIR, sub_dir, sub_sub_dir, filename)\n",
    "                    if filename.endswith('xml'):\n",
    "                        new_filename = os.path.join(LD3K_DS_DIR, 'labels/train', sub_dir+'_'+sub_sub_dir+'_'+filename.replace('xml', 'txt'))\n",
    "                        file_object = open(old_filename, encoding='utf-8')                                                                                                            \n",
    "                        try:\n",
    "                            all_the_xmlStr = file_object.read()\n",
    "                        finally:\n",
    "                            file_object.close()\n",
    "                        convertedDict = xmltodict.parse(all_the_xmlStr)\n",
    "                #         print(len(convertedDict['annotation']['object']))\n",
    "                        if 'object' in convertedDict['annotation']:\n",
    "                            fix_width = int(convertedDict['annotation']['size']['width'])\n",
    "                            fix_height = int(convertedDict['annotation']['size']['height'])\n",
    "                            \n",
    "                            objs = convertedDict['annotation']['object']\n",
    "                            if not isinstance(objs,list):\n",
    "                                objs = [objs]\n",
    "                #                 print('objs:', objs)\n",
    "                            with open(new_filename, 'w') as fout:\n",
    "                                for annotation in objs:\n",
    "                                    # class_id = 0\n",
    "                                    if annotation['name'] not in class_names_map:\n",
    "                                        class_names_map[annotation['name']] = len(class_names_map)\n",
    "                                    class_id = class_names_map[annotation['name']]\n",
    "\n",
    "                                    xmin = int(annotation['bndbox']['xmin'])\n",
    "                                    ymin = int(annotation['bndbox']['ymin'])\n",
    "                                    xmax = int(annotation['bndbox']['xmax'])\n",
    "                                    ymax = int(annotation['bndbox']['ymax'])\n",
    "\n",
    "                                    w = xmax-xmin\n",
    "                                    h = ymax-ymin\n",
    "\n",
    "                                    if w>0 and h>0:\n",
    "                                        center_x = (xmin+xmax)/2\n",
    "                                        center_y = (ymin+ymax)/2\n",
    "                                        fout.write(str(class_id)+' '+str(center_x/fix_width)+' '+str(center_y/fix_height)+' '+str(w/fix_width)+' '+str(h/fix_height)+'\\n')\n",
    "                                        fout.write(str(0)+' '+str(center_x/fix_width)+' '+str(center_y/fix_height)+' '+str(w/fix_width)+' '+str(h/fix_height)+'\\n')\n",
    "                        else:\n",
    "                            print('Delete', old_filename)\n",
    "                            os.remove(old_filename)\n",
    "                    elif filename.endswith('jpg'):\n",
    "                        new_filename = os.path.join(LD3K_DS_DIR, 'images/train', sub_dir+'_'+sub_sub_dir+'_'+filename)\n",
    "                        shutil.copy(old_filename, new_filename)\n",
    "                    else:\n",
    "                        print('Warning:', old_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a10245f8-845d-42a7-999e-2dbba56cf2e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158654 126923 31731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31731/31731 [00:04<00:00, 6545.53it/s] \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "将训练数据切分成训练集和验证集\n",
    "'''\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "filenames = os.listdir(os.path.join(LD3K_DS_DIR, 'images/train'))\n",
    "train_filenames, test_filenames = train_test_split(filenames, test_size=0.2)\n",
    "print(len(filenames), len(train_filenames), len(test_filenames))\n",
    "for filename in tqdm(test_filenames):\n",
    "    old_filename = os.path.join(LD3K_DS_DIR, 'images/train', filename)\n",
    "    new_filename = os.path.join(LD3K_DS_DIR, 'images/val', filename)\n",
    "    shutil.move(old_filename, new_filename)\n",
    "    \n",
    "    old_filename = os.path.join(LD3K_DS_DIR, 'labels/train', filename.replace('jpg', 'txt'))\n",
    "    new_filename = os.path.join(LD3K_DS_DIR, 'labels/val', filename.replace('jpg', 'txt'))\n",
    "    if os.path.exists(old_filename):\n",
    "        shutil.move(old_filename, new_filename)\n",
    "    else:\n",
    "        print('Not exist:', old_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b505af4-63d2-4521-82fa-33aba59566a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names_map: 2994\n"
     ]
    }
   ],
   "source": [
    "print('class_names_map:', len(class_names_map))\n",
    "\n",
    "# 创建logo3k训练需要的配置文件，训练脚本会加载这个配置文件，因此需要按照sagemaker训练容器中的路径指定训练数据的‘path’\n",
    "cfg_path = os.path.join(LD3K_DATA_DIR, 'cfg', 'LogoDet-3K.yaml')\n",
    "with open(cfg_path, 'w') as fout:\n",
    "    fout.write('path: ' + '/opt/ml/input/data/' + '  # dataset root dir\\n')\n",
    "    fout.write('train: images/train  # train images (relative to \\'path\\')\\n')\n",
    "    fout.write('val: images/val  # val images (relative to \\'path\\')\\n')\n",
    "    fout.write('test:  # test images (optional)\\n')\n",
    "    fout.write('names:\\n')\n",
    "    for k,v in class_names_map.items():\n",
    "        fout.write('  '+str(v)+': '+str(k)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f03e1-4bd7-49cd-bfaa-4c116e5e92cc",
   "metadata": {},
   "source": [
    "将logo3k数据通过s5cmd上传到s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a572f554-d8c0-4f13-9b1c-c833b6059d65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRN_BUCKET=sagemaker-us-west-2-935206693453\n",
      "env: PRE=fw-logo-detection\n"
     ]
    }
   ],
   "source": [
    "# 指定要上传的s3 bucket，和上传到bucket中哪个prefix（文件夹）下\n",
    "%env TRN_BUCKET=sagemaker-us-west-2-935206693453 \n",
    "%env PRE=fw-logo-detection\n",
    "\n",
    "#!aws s3api put-object --bucket $TRN_BUCKET --key $PRE\n",
    "#!docker run --rm -v $(pwd):/aws -v ~/.aws:/root/.aws s5cmd rm s3://sagemaker-us-west-2-935206693453/fw-logo-detection/* 1>/dev/null\n",
    "!docker run --rm -v $(pwd):/aws -v ~/.aws:/root/.aws s5cmd sync /aws/train_data s3://$TRN_BUCKET/$PRE/ 1>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b7c7b-082d-4603-a314-b10e27da4c6c",
   "metadata": {},
   "source": [
    "## 2. 基于LogoDet-3K数据进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d27cfe-52c5-4557-9ba0-764c9661abce",
   "metadata": {},
   "source": [
    "初始化操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca628bce-76c9-405d-992d-b10fb5ac78ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.146.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "print(sagemaker.__version__)\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae557b2-0b45-4ec7-a3e6-06ca59d14b1e",
   "metadata": {},
   "source": [
    "准备Sagemaker训练任务的input参数，input中的s3数据会被复制到训练容器的 /opt/ml/input/data/ 目录中。并且会以channel名为子文件夹名存储对应的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3477a54-3bad-411a-8658-264b996712cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cfg': 's3://sagemaker-us-west-2-935206693453/fw-logo-detection/train_data/LogoDet-3K/cfg', 'images': 's3://sagemaker-us-west-2-935206693453/fw-logo-detection/train_data/LogoDet-3K/datasets/images', 'labels': 's3://sagemaker-us-west-2-935206693453/fw-logo-detection/train_data/LogoDet-3K/datasets/labels'}\n"
     ]
    }
   ],
   "source": [
    "TRN_BUCKET='sagemaker-us-west-2-935206693453'\n",
    "PRE='fw-logo-detection'\n",
    "LD3K_PRE=PRE + '/' + LD3K_DATA_DIR\n",
    "data_location = 's3://{}/{}'.format(TRN_BUCKET, LD3K_PRE)\n",
    "\n",
    "logo3k_inputs = {\n",
    "    'cfg': data_location+'/cfg', \n",
    "    #'weights': data_location+'/weights', \n",
    "    'images': data_location+'/datasets/images', \n",
    "    'labels': data_location+'/datasets/labels'}\n",
    "print(logo3k_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e69fb78b-33df-4234-8aa4-4045f35c8662",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-06-20-06-13-39-318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-20 06:13:39 Starting - Starting the training job."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_981/2508439410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m             )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogo3k_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2342\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2345\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   4704\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4706\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4708\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparameters = {'data': '/opt/ml/input/data/cfg/LogoDet-3K.yaml', \n",
    "                   'weight': 'yolov8s.pt', # 使用yolo预训练好的参数\n",
    "                   'project': '/opt/ml/model/',\n",
    "                   'name': 'fw-logo-detection', 'imgsz': 640, 'batch': 4, 'epochs': 1, 'workers':1}  # Single CPU or GPU\n",
    "                   # 'name': 'fw-logo-detection', 'imgsz': 640, 'batch': 12, 'epochs': 1, 'device': '0,1,2,3', 'workers':1}  # Multi-GPU: DP Mode\n",
    "\n",
    "instance_type = 'ml.p3.2xlarge'  # 'ml.p3.2xlarge' or 'ml.p3.8xlarge' or ...\n",
    "\n",
    "\n",
    "metric_definitions = [{'Name': 'mAP50',\n",
    "                       'Regex': '^all\\s+(?:[\\d.]+\\s+){4}([\\d.]+)'}]\n",
    "\n",
    "logo3k_estimator = PyTorch(entry_point='train.py',\n",
    "                            source_dir='./code/',\n",
    "                            role=role,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            framework_version='1.13.1', # 2.0.1\n",
    "                            py_version='py39', # py310\n",
    "                            # framework_version='2.0.1',\n",
    "                            # py_version='py310',\n",
    "                            script_mode=True,\n",
    "                            instance_count=1,  # 1 or 2 or ...\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            instance_type=instance_type,\n",
    "                            # distribution={\n",
    "                            #     \"torch_distributed\": {\n",
    "                            #         \"enabled\": True\n",
    "                            #     }\n",
    "                            # }\n",
    "            )\n",
    "\n",
    "estimator.fit(logo3k_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5fb865-1ebb-4865-ac61-e178d015708a",
   "metadata": {},
   "source": [
    "## 3. 准备FreeWheel-5K数据到S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90467521-dee0-4197-beb3-366d67b0a685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_names: 1182\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "按照video name组织数据，基于#对视频文件名进行拆解\n",
    "按照dict[str, list]的方式组织，key是video name，value是包含对应文件名的列表\n",
    "'''\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_dir = 'train_data/FreeWheel-5K-by-video-name/datasets/images/train'\n",
    "filenames = os.listdir(base_dir)\n",
    "video_names = {}\n",
    "for filename in filenames:\n",
    "    video_name = filename.split('#')[0]\n",
    "    if video_name not in video_names:\n",
    "        video_names[video_name] = []\n",
    "    video_names[video_name].append(filename)\n",
    "print('video_names:', len(video_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae771630-9dde-41f0-9fed-6c3997ca4dde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945 237\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "按照8:2的比例拆分训练集和数据集\n",
    "基于上一步video name dict的结果进行拆分，将val数据集从image/train复制到image/val\n",
    "'''\n",
    "train_video_names, val_video_names = train_test_split(list(video_names.keys()), test_size=0.2)\n",
    "for video_name in val_video_names:\n",
    "    val_filenames = video_names[video_name]\n",
    "    for filename in val_filenames:\n",
    "        if filename.endswith('jpg'):\n",
    "            filename = os.path.join(base_dir, filename)\n",
    "            shutil.move(filename, filename.replace('images/train', 'images/val'))\n",
    "            label_filename = filename.replace('jpg', 'txt').replace('images', 'labels')\n",
    "            if os.path.exists(label_filename):\n",
    "                shutil.move(label_filename, label_filename.replace('labels/train', 'labels/val'))\n",
    "print(len(train_video_names), len(val_video_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d06667a-72db-4465-9741-1b5c071cbd9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-06-19 16:55:03 Starting - Preparing the instances for training\n",
      "2023-06-19 16:55:03 Downloading - Downloading input data\n",
      "2023-06-19 16:55:03 Training - Training image download completed. Training in progress.\n",
      "2023-06-19 16:55:03 Uploading - Uploading generated training model\n",
      "2023-06-19 16:55:03 Completed - Training job completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-935206693453/pytorch-training-2023-06-19-14-24-52-624/output/model.tar.gz'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取logo3k的模型best.pt文件，用于下一步增量训练\n",
    "logo3k_estimator = PyTorch.attach('pytorch-training-2023-06-19-14-24-52-624')\n",
    "logo3k_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5124fc9f-ee22-4015-bda7-232c85d5f392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fw-logo-detection/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "# 将s3路径替换为上一步中得到的sm training job的模型数据路径\n",
    "!docker run --rm -v $(pwd):/aws -v ~/.aws:/root/.aws s5cmd cp 's3://sagemaker-us-west-2-935206693453/pytorch-training-2023-06-19-14-24-52-624/output/model.tar.gz' /aws/ 1>/dev/null\n",
    "!tar -zxv -C train_data/FreeWheel-5K-by-video-name/weights/ -f model.tar.gz --strip-components=2 fw-logo-detection/weights/best.pt\n",
    "!rm -rf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb86b1ef-343e-48a5-aba1-f7e9627d316b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "创建freewheel-5k的yolo config文件\n",
    "'''\n",
    "class_names_map = {}\n",
    "\n",
    "with open('raw_data/image-data-4.28/labels.txt', 'r') as fin:\n",
    "    lines = fin.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        class_names_map[line.strip()] = i\n",
    "\n",
    "with open('train_data/FreeWheel-5K-by-video-name/cfg/FreeWheel-5K-by-video-name.yaml', 'w') as fout:\n",
    "    fout.write('path: /opt/ml/input/data/  # dataset root dir\\n')\n",
    "    fout.write('train: images/train  # train images (relative to \\'path\\')\\n')\n",
    "    fout.write('val: images/val  # val images (relative to \\'path\\')\\n')\n",
    "    fout.write('test:  # test images (optional)\\n')\n",
    "    fout.write('names:\\n')\n",
    "    for k,v in class_names_map.items():\n",
    "        fout.write('  '+str(v)+': '+str(k)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "457b7ba1-2391-4eda-9083-fa1def7644b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将数据同步到s3中\n",
    "!docker run --rm -v $(pwd):/aws -v ~/.aws:/root/.aws s5cmd sync /aws/train_data s3://$TRN_BUCKET/$PRE/ 1>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4a2a8-d10c-4a81-85b1-2e64a0ba9005",
   "metadata": {},
   "source": [
    "## 3. 基于FW-5k数据进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64c2e642-ebc6-492c-be10-a27693e82eed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cfg': 's3://sagemaker-us-west-2-935206693453/fw-logo-detection/train_data/FreeWheel-5K-by-video-name/cfg', 'weights': 's3://sagemaker-us-west-2-935206693453/fw-logo-detection/train_data/FreeWheel-5K-by-video-name/weights', 'images': 's3://sagemaker-us-west-2-935206693453/fw-logo-detection/train_data/FreeWheel-5K-by-video-name/datasets/images', 'labels': 's3://sagemaker-us-west-2-935206693453/fw-logo-detection/train_data/FreeWheel-5K-by-video-name/datasets/labels'}\n"
     ]
    }
   ],
   "source": [
    "DET_DATA_DIR = 'train_data'\n",
    "FW5K_DATA_DIR = DET_DATA_DIR + '/' + 'FreeWheel-5K-by-video-name'\n",
    "FW5K_DS_DIR = FW5K_DATA_DIR + '/' + 'datasets'\n",
    "\n",
    "TRN_BUCKET='sagemaker-us-west-2-935206693453'\n",
    "PRE='fw-logo-detection'\n",
    "FW5K_PRE=PRE + '/' + FW5K_DATA_DIR\n",
    "data_location = 's3://{}/{}'.format(TRN_BUCKET, FW5K_PRE)\n",
    "fw5k_inputs = {'cfg': data_location+'/cfg', 'weights': data_location+'/weights', 'images': data_location+'/datasets/images', 'labels': data_location+'/datasets/labels'}\n",
    "print(fw5k_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6fe9ff2-4a0d-4a4d-9b77-b9ec328851d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-06-20-06-15-09-227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-20 06:15:09 Starting - Starting the training job."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_981/1594354467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                             instance_type=instance_type)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfw5k_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2342\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2345\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   4704\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4706\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4708\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparameters = {'data': '/opt/ml/input/data/cfg/FreeWheel-5K-by-video-name.yaml', \n",
    "                   'weight': '/opt/ml/input/data/weights/best.pt',\n",
    "                   'project': '/opt/ml/model/',\n",
    "                   'name': 'fw-logo-detection', 'imgsz': 640, 'batch': 4, 'epochs': 20}  # Single CPU or GPU\n",
    "#                    'name': 'fw-logo-detection', 'imgsz': 640, 'batch': 16, 'epochs': 5, 'device': '0,1,2,3'}  # Multi-GPU: DP Mode\n",
    "\n",
    "instance_type = 'ml.p3.2xlarge'  # 'ml.p3.2xlarge' or 'ml.p3.8xlarge' or ...\n",
    "\n",
    "\n",
    "metric_definitions = [{'Name': 'mAP50',\n",
    "                       'Regex': '^all\\s+(?:[\\d.]+\\s+){4}([\\d.]+)'}]\n",
    "\n",
    "fw5k_estimator = PyTorch(entry_point='train.py',\n",
    "                            source_dir='./code/',\n",
    "                            role=role,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            framework_version='1.13.1',\n",
    "                            py_version='py39',\n",
    "                            script_mode=True,\n",
    "                            instance_count=1,  # 1 or 2 or ...\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            instance_type=instance_type)\n",
    "\n",
    "estimator.fit(fw5k_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41cb5b-9a9d-4922-b682-d2f6edacd480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
